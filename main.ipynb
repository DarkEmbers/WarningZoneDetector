{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import asyncio\n",
    "from FeetModel import KeypointPredictor\n",
    "import math\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarningZoneDetector:\n",
    "\tdef __init__(self):\n",
    "\t\tself.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\t\tself.model = YOLO(\"./Models/yolov8x-pose.pt\").to(self.device)\n",
    "\t\tself.points = []\n",
    "\t\tself.loss = []\n",
    "\n",
    "\tdef onMouseClick(self, event, x, y, flags, param):\n",
    "\t\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\t\tprint(x, y)\n",
    "\t\t\tself.points.append((x, y))\n",
    "\n",
    "\n",
    "\tdef draw_overlap(self, polygon_points, frame, l_foot, r_foot):\n",
    "\t\t# Not enough points to form a polygon\n",
    "\t\tif len(polygon_points) < 3:\n",
    "\t\t\treturn False\n",
    "\n",
    "\t\tuser_polygon = np.array(polygon_points, np.int32)\n",
    "\t\tis_overlap = False\n",
    "\n",
    "\t\t# Check if either foot is inside the polygon\n",
    "\t\tif cv2.pointPolygonTest(user_polygon, l_foot, False) > 0:\n",
    "\t\t\tis_overlap = True\n",
    "\t\t\tcv2.circle(frame, l_foot, 5, (0, 0, 255), -1)\n",
    "\n",
    "\t\tif cv2.pointPolygonTest(user_polygon, r_foot, False) > 0:\n",
    "\t\t\tis_overlap = True\n",
    "\t\t\tcv2.circle(frame, r_foot, 5, (0, 0, 255), -1)\n",
    "\n",
    "\t\treturn is_overlap\n",
    "\n",
    "\tdef predict_foot(self, l_shoulder, r_shoulder, l_hip, r_hip, keypoint_pred_model):\n",
    "\t\t# Pytorch deep learning\n",
    "\t\tdevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\t\tinputs = torch.tensor([l_shoulder[0], l_shoulder[1], r_shoulder[0], r_shoulder[1], l_hip[0], l_hip[1], r_hip[0], r_hip[1]], dtype=torch.float32).to(device)\n",
    "\t\tresult = keypoint_pred_model(inputs)\n",
    "\t\treturn (result[0], result[1]), (result[2], result[3])\n",
    "\n",
    "\tdef process_frame(self, frame):\n",
    "\t\tsmall_frame = cv2.resize(frame, (640, 480))\n",
    "\t\tresults = self.model(source=small_frame, conf=0.3, save=False, classes=[0], verbose=False)\n",
    "\t\treturn results[0]\n",
    "\t\n",
    "\tdef run(self, video_path):\n",
    "\t\t# Testing with youtube videos\n",
    "\t\t# -----------------------\n",
    "\t\tsource = cv2.VideoCapture(video_path)\n",
    "\t\t# -----------------------\n",
    "\n",
    "\t\t# source  = cv2.VideoCapture(0)\n",
    "\t\tcv2.namedWindow(\"YOLO Output\")\n",
    "\t\tcv2.setMouseCallback(\"YOLO Output\", self.onMouseClick)\n",
    "\n",
    "\t\t# Points of zone\n",
    "\t\tpoints = []\n",
    "\n",
    "\t\t# For FPS calculation\n",
    "\t\tnew_frame_time = 0\n",
    "\t\tprev_frame_time = 0\n",
    "\n",
    "\t\t# font which we will be using to display FPS \n",
    "\t\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\t\tsmall_frame_height, small_frame_width = 480, 640  # The resized small frame used in process_frame\n",
    "\n",
    "\t\tkeypoint_pred_model = KeypointPredictor().to(self.device)\n",
    "\t\tkeypoint_pred_model.load_state_dict(torch.load(\"./Models/FeetPredict.pt\"))\n",
    "\n",
    "\t\tstart_time = time.time()\n",
    "\t\twhile True:\n",
    "\t\t\tret, frame = source.read()\n",
    "\t\t\tframe_height, frame_width = frame.shape[:2]\n",
    "\n",
    "\t\t\t# Detect objects every n frames\n",
    "\t\t\tresults = self.process_frame(frame)\n",
    "\t\t\t\n",
    "\t\t\t# Draw only the foot keypoints (keypoints 15: left foot, 16: right foot)\n",
    "\t\t\tkeypoints = results.keypoints.xy\n",
    "\t\t\tfor person_keypoints in keypoints:\n",
    "\t\t\t\tleft_foot = person_keypoints[15][:2].tolist()\n",
    "\t\t\t\tright_foot = person_keypoints[16][:2].tolist()\n",
    "\t\t\t\tleft_shoulder = person_keypoints[5][:2].tolist()\n",
    "\t\t\t\tright_shoulder = person_keypoints[6][:2].tolist()\n",
    "\t\t\t\tl_hip = person_keypoints[11][:2].tolist()\n",
    "\t\t\t\tr_hip = person_keypoints[12][:2].tolist()\n",
    "\n",
    "\t\t\t\t# Predict feet points if ears and hips are visible and feet are not visible\n",
    "\t\t\t\tif left_shoulder != [0, 0] and right_shoulder != [0, 0] and l_hip != [0, 0] and r_hip != [0, 0] and left_foot == [0, 0] and right_foot == [0, 0]:\n",
    "\t\t\t\t\tleft_shoulder = tuple(map(int, person_keypoints[5][:2]))  # Left shoulder [x, y]\n",
    "\t\t\t\t\tright_shoulder = tuple(map(int, person_keypoints[6][:2]))  # Right shoulder [x, y]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Use distance between shoulders and hip \n",
    "\t\t\t\t\t# points to calculate foot positions\n",
    "\t\t\t\t\tleft_hip = tuple(map(int, person_keypoints[11][:2]))  # Left hip [x, y]\n",
    "\t\t\t\t\tright_hip = tuple(map(int, person_keypoints[12][:2]))  # Right hip [x, y]\n",
    "\n",
    "\t\t\t\t\tleft_foot, right_foot = self.predict_foot(left_shoulder, right_shoulder, left_hip, right_hip, keypoint_pred_model)\n",
    "\n",
    "\t\t\t\tif left_foot != [0, 0] and right_foot != [0, 0]:\n",
    "\t\t\t\t\t# Scale the coordinates back to the original frame size\n",
    "\t\t\t\t\tleft_foot = (\n",
    "\t\t\t\t\t\tint(left_foot[0] * frame_width / small_frame_width),\n",
    "\t\t\t\t\t\tint(left_foot[1] * frame_height / small_frame_height)\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\tright_foot = (\n",
    "\t\t\t\t\t\tint(right_foot[0] * frame_width / small_frame_width),\n",
    "\t\t\t\t\t\tint(right_foot[1] * frame_height / small_frame_height)\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\t# Draw the left foot keypoint\n",
    "\t\t\t\t\tcv2.circle(frame, left_foot, 5, (0, 255, 0), -1)  # Green for left foot\n",
    "\n",
    "\t\t\t\t\t# Draw the right foot keypoint\n",
    "\t\t\t\t\tcv2.circle(frame, right_foot, 5, (9, 255, 0), -1)  # Blue for right foot\n",
    "\n",
    "\t\t\t\t\tself.draw_overlap(self.points, frame, left_foot, right_foot)\n",
    "\n",
    "\t\t\t# Plot polygons or any other features you need\n",
    "\t\t\tfor i, point in enumerate(self.points):\n",
    "\t\t\t\tcv2.circle(frame, point, 5, (243, 211, 74), 2)\n",
    "\t\t\t\tif len(self.points) > 1:\n",
    "\t\t\t\t\tnext_point = self.points[i+1] if i < len(self.points)-1 else self.points[0]\n",
    "\t\t\t\t\tcv2.line(frame, point, next_point, (243, 211, 74), 2)\n",
    "\n",
    "\t\t\t# time when we finish processing for this frame\n",
    "\t\t\tnew_frame_time = time.time()\n",
    "\t\t\n",
    "\t\t\t# Calculate FPS\n",
    "\t\t\tfps = 1 / (new_frame_time-prev_frame_time) \n",
    "\t\t\tprev_frame_time = new_frame_time \n",
    "\t\t\tfps = \"FPS: \" + str(int(fps))\n",
    "\t\t\tcv2.putText(frame, fps, (frame.shape[1]-200, 60), font, 1.5, (0, 0, 0), 7, cv2.LINE_AA)\n",
    "\t\t\tcv2.putText(frame, fps, (frame.shape[1]-200, 60), font, 1.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\t\t\t\n",
    "\t\t\t# frame = cv2.resize(frame, (frame.shape[1], frame.shape[0]))\n",
    "\t\t\tcv2.imshow(\"YOLO Output\", frame)\n",
    "\t\t\t\n",
    "\t\t\tif cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\t# stop after 15 seconds of video\n",
    "\t\t\tif time.time() - start_time > 15:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tsource.release()\n",
    "\t\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722 372\n",
      "913 422\n",
      "928 591\n",
      "604 656\n"
     ]
    }
   ],
   "source": [
    "zone_det = WarningZoneDetector()\n",
    "zone_det.run(\"./Media/HD CCTV Camera video 3MP 4MP iProx CCTV HDCCTVCameras.net retail store.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): PoseModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Pose(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (cv4): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 51, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 51, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to load model\n",
    "path = \"./Models/yolov8x-pose.pt\"\n",
    "if Path(path).exists():\n",
    "    model = YOLO(\"./Models/yolov8x-pose.pt\")\n",
    "\n",
    "else:\n",
    "    # Build from YAML and transfer weights\n",
    "    model = YOLO(\"yolov8x-pose.yaml\").load(\"./Models/yolov8x-pose.pt\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensorRT\n",
    "# model.export(format=\"engine\", int8=True)\n",
    "# model.export(format=\"engine\", half=False)\n",
    "# model.export(format=\"engine\", half=True)\n",
    "\n",
    "model = YOLO(\"./Models/yolov8x-pose-f32.engine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onMouseClick(event, x, y, flags, param):\n",
    "\tglobal points\n",
    "\n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tprint(x, y)\n",
    "\t\tpoints.append((x, y))\n",
    "\n",
    "\n",
    "def draw_overlap(polygon_points, frame, l_foot, r_foot):\n",
    "\t# Not enough points to form a polygon\n",
    "\tif len(polygon_points) < 3:\n",
    "\t\treturn False\n",
    "\n",
    "\tuser_polygon = np.array(polygon_points, np.int32)\n",
    "\tis_overlap = False\n",
    "\n",
    "\t# Check if either foot is inside the polygon\n",
    "\tif cv2.pointPolygonTest(user_polygon, l_foot, False) > 0:\n",
    "\t\tis_overlap = True\n",
    "\t\tcv2.circle(frame, l_foot, 5, (0, 0, 255), -1)\n",
    "\n",
    "\tif cv2.pointPolygonTest(user_polygon, r_foot, False) > 0:\n",
    "\t\tis_overlap = True\n",
    "\t\tcv2.circle(frame, r_foot, 5, (0, 0, 255), -1)\n",
    "\n",
    "\treturn is_overlap\n",
    "\n",
    "def predict_foot(l_shoulder, r_shoulder, l_hip, r_hip, keypoint_pred_model, model=\"torch\"):\n",
    "\n",
    "\tif model == \"torch\":\n",
    "\t\t# Pytorch deep learning\n",
    "\t\tdevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\t\tinputs = torch.tensor([l_shoulder[0], l_shoulder[1], r_shoulder[0], r_shoulder[1], l_hip[0], l_hip[1], r_hip[0], r_hip[1]], dtype=torch.float32).to(device)\n",
    "\t\tresult = keypoint_pred_model(inputs)\n",
    "\t\treturn (result[0], result[1]), (result[2], result[3])\n",
    "\n",
    "\telse:\n",
    "\t\t# sklearn linear regression\n",
    "\t\tinputs = np.array([l_shoulder[0], l_shoulder[1], r_shoulder[0], r_shoulder[1], l_hip[0], l_hip[1], r_hip[0], r_hip[1]])\n",
    "\t\tresult = keypoint_pred_model.predict(inputs.reshape(1, -1))[0]\n",
    "\t\treturn (result[0], result[1]), (result[2], result[3])\n",
    "\n",
    "\n",
    "async def process_frame(frame):\n",
    "\tsmall_frame = cv2.resize(frame, (640, 480))\n",
    "\tresults = await asyncio.to_thread(model, source=small_frame, conf=0.3, save=False, classes=[0], verbose=False)\n",
    "\treturn results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "\tglobal points\n",
    "\n",
    "\tglobal loss\n",
    "\tloss = []\n",
    "\n",
    "\t# Testing with youtube videos\n",
    "\t# -----------------------\n",
    "\tsource = cv2.VideoCapture(\"./Media/HD CCTV Camera video 3MP 4MP iProx CCTV HDCCTVCameras.net retail store.mp4\")\n",
    "\t# -----------------------\n",
    "\n",
    "\t# source  = cv2.VideoCapture(0)\n",
    "\tcv2.namedWindow(\"YOLO Output\")\n",
    "\tcv2.setMouseCallback(\"YOLO Output\", onMouseClick)\n",
    "\n",
    "\t# Points of zone\n",
    "\tpoints = []\n",
    "\n",
    "\t# For FPS calculation\n",
    "\tnew_frame_time = 0\n",
    "\tprev_frame_time = 0\n",
    "\n",
    "\t# Frame skipper\n",
    "\tframe_skip = 1 # Not skipping frames at the moment\n",
    "\tframe_count = 0\n",
    "\n",
    "\t# font which we will be using to display FPS \n",
    "\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\tsmall_frame_height, small_frame_width = 480, 640  # The resized small frame used in process_frame\n",
    "\n",
    "\tmodel_type = \"torch\"\n",
    "\tif model_type == \"torch\":\n",
    "\t\tkeypoint_pred_model = KeypointPredictor().to(device)\n",
    "\t\tkeypoint_pred_model.load_state_dict(torch.load(\"./Models/FeetPredict.pt\"))\n",
    "\n",
    "\telse:\n",
    "\t\tkeypoint_pred_model = joblib.load(\"./Models/LinearRegression_FeetPredict.pkl\")\n",
    "\n",
    "\tstart_time = time.time()\n",
    "\twhile True:\n",
    "\t\tret, frame = source.read()\n",
    "\t\tframe_height, frame_width = frame.shape[:2]\n",
    "\n",
    "\t\t# Detect objects every n frames\n",
    "\t\tif frame_count % frame_skip == 0:\n",
    "\t\t\tresults = await process_frame(frame)\n",
    "\t\t\tframe_count = 0\n",
    "\t\t\n",
    "\t\tframe_count += 1\n",
    "\t\t\n",
    "\t\t# Draw only the foot keypoints (keypoints 15: left foot, 16: right foot)\n",
    "\t\tkeypoints = results.keypoints.xy\n",
    "\t\tfor person_keypoints in keypoints:\n",
    "\t\t\tleft_foot = person_keypoints[15][:2].tolist()\n",
    "\t\t\tright_foot = person_keypoints[16][:2].tolist()\n",
    "\t\t\tleft_shoulder = person_keypoints[5][:2].tolist()\n",
    "\t\t\tright_shoulder = person_keypoints[6][:2].tolist()\n",
    "\t\t\tl_hip = person_keypoints[11][:2].tolist()\n",
    "\t\t\tr_hip = person_keypoints[12][:2].tolist()\n",
    "\n",
    "\t\t\t# Predict feet points if ears and hips are visible and feet are not visible\n",
    "\t\t\t# if left_shoulder != [0, 0] and right_shoulder != [0, 0] and l_hip != [0, 0] and r_hip != [0, 0] and left_foot == [0, 0] and right_foot == [0, 0]:\n",
    "\t\t\tif left_shoulder != [0, 0] and right_shoulder != [0, 0] and l_hip != [0, 0] and r_hip != [0, 0] and left_foot != [0, 0] and right_foot != [0, 0]: # For loss calculation\n",
    "\t\t\t\tleft_shoulder = tuple(map(int, person_keypoints[5][:2]))  # Left shoulder [x, y]\n",
    "\t\t\t\tright_shoulder = tuple(map(int, person_keypoints[6][:2]))  # Right shoulder [x, y]\n",
    "\n",
    "\t\t\t\t# For testing\n",
    "\t\t\t\tcv2.circle(frame, (\n",
    "\t\t\t\t\tint(left_shoulder[0] * frame_width / small_frame_width),\n",
    "\t\t\t\t\tint(left_shoulder[1] * frame_height / small_frame_height)\n",
    "\t\t\t\t), 5, (0, 0, 255), -1)\n",
    "\n",
    "\t\t\t\tcv2.circle(frame, (\n",
    "\t\t\t\t\tint(right_shoulder[0] * frame_width / small_frame_width),\n",
    "\t\t\t\t\tint(right_shoulder[1] * frame_height / small_frame_height)\n",
    "\t\t\t\t), 5, (0, 0, 255), -1)\n",
    "\t\t\t\t#############################\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Use distance between shoulders and hip \n",
    "\t\t\t\t# points to calculate foot positions\n",
    "\t\t\t\tleft_hip = tuple(map(int, person_keypoints[11][:2]))  # Left hip [x, y]\n",
    "\t\t\t\tright_hip = tuple(map(int, person_keypoints[12][:2]))  # Right hip [x, y]\n",
    "\n",
    "\t\t\t\t# For testing\n",
    "\t\t\t\tcv2.circle(frame, (\n",
    "\t\t\t\t\tint(left_hip[0] * frame_width / small_frame_width),\n",
    "\t\t\t\t\tint(left_hip[1] * frame_height / small_frame_height)\n",
    "\t\t\t\t), 5, (255, 0, 255), -1)\n",
    "\t\t\t\tcv2.circle(frame, (\n",
    "\t\t\t\t\tint(right_hip[0] * frame_width / small_frame_width),\n",
    "\t\t\t\t\tint(right_hip[1] * frame_height / small_frame_height)\n",
    "\t\t\t\t), 5, (255, 0, 255), -1)\n",
    "\t\t\t\t############################\n",
    "\n",
    "\t\t\t\tground_truth_l_foot = left_foot\n",
    "\t\t\t\tground_truth_r_foot = right_foot\n",
    "\n",
    "\t\t\t\t# feet are same distance from hip as hip is same distance from shoulder\n",
    "\t\t\t\t# l_dist = np.abs(left_shoulder[1] - left_hip[1])\n",
    "\t\t\t\t# r_dist = np.abs(right_shoulder[1] - right_hip[1])\n",
    "\n",
    "\t\t\t\t# left_foot = (left_hip[0], left_hip[1] + (l_dist * 1.3))\n",
    "\t\t\t\t# right_foot = (right_hip[0], right_hip[1] + (r_dist * 1.3))\n",
    "\n",
    "\t\t\t\tleft_foot, right_foot = predict_foot(left_shoulder, right_shoulder, left_hip, right_hip, keypoint_pred_model, model=model_type)\n",
    "\n",
    "\t\t\t\t# Loss calculation\n",
    "\t\t\t\t# Calculate the distance between predicted feet and ground truth feet\n",
    "\t\t\t\tl_dist = math.dist(left_foot, ground_truth_l_foot)\n",
    "\t\t\t\tr_dist = math.dist(right_foot, ground_truth_r_foot)\n",
    "\t\t\t\tloss.append(np.mean([l_dist, r_dist]))\n",
    "\n",
    "\t\t\t# if left_foot != [0, 0] and right_foot != [0, 0]:\n",
    "\t\t\tif left_shoulder != [0, 0] and right_shoulder != [0, 0] and l_hip != [0, 0] and r_hip != [0, 0] and left_foot != [0, 0] and right_foot != [0, 0]: # For loss calculation\n",
    "\t\t\t\t# Scale the coordinates back to the original frame size\n",
    "\t\t\t\tleft_foot = (\n",
    "\t\t\t\t\tint(left_foot[0] * frame_width / small_frame_width),\n",
    "\t\t\t\t\tint(left_foot[1] * frame_height / small_frame_height)\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\tright_foot = (\n",
    "\t\t\t\t\tint(right_foot[0] * frame_width / small_frame_width),\n",
    "\t\t\t\t\tint(right_foot[1] * frame_height / small_frame_height)\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\t# Draw the left foot keypoint\n",
    "\t\t\t\tcv2.circle(frame, left_foot, 5, (0, 255, 0), -1)  # Green for left foot\n",
    "\n",
    "\t\t\t\t# Draw the right foot keypoint\n",
    "\t\t\t\tcv2.circle(frame, right_foot, 5, (9, 255, 0), -1)  # Blue for right foot\n",
    "\n",
    "\t\t\t\tdraw_overlap(points, frame, left_foot, right_foot)\n",
    "\n",
    "\t\t# Plot polygons or any other features you need\n",
    "\t\tfor i, point in enumerate(points):\n",
    "\t\t\tcv2.circle(frame, point, 5, (243, 211, 74), 2)\n",
    "\t\t\tif len(points) > 1:\n",
    "\t\t\t\tnext_point = points[i+1] if i < len(points)-1 else points[0]\n",
    "\t\t\t\tcv2.line(frame, point, next_point, (243, 211, 74), 2)\n",
    "\n",
    "\t\t# time when we finish processing for this frame\n",
    "\t\tnew_frame_time = time.time()\n",
    "\t\n",
    "\t\t# Calculate FPS\n",
    "\t\tfps = 1 / (new_frame_time-prev_frame_time) \n",
    "\t\tprev_frame_time = new_frame_time \n",
    "\t\tfps = \"FPS: \" + str(int(fps))\n",
    "\t\tcv2.putText(frame, fps, (frame.shape[1]-200, 60), font, 1.5, (0, 0, 0), 7, cv2.LINE_AA)\n",
    "\t\tcv2.putText(frame, fps, (frame.shape[1]-200, 60), font, 1.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\t\t\n",
    "\t\t# frame = cv2.resize(frame, (frame.shape[1], frame.shape[0]))\n",
    "\t\tcv2.imshow(\"YOLO Output\", frame)\n",
    "\t\t\n",
    "\t\tif cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# stop after 15 seconds of video\n",
    "\t\tif time.time() - start_time > 15:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tsource.release()\n",
    "\tcv2.destroyAllWindows()\n",
    "\t\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.471382819123939"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
