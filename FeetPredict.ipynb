{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations for training\n",
    "train_ann_path = Path('./Data/coco2017/annotations/person_keypoints_train2017.json')\n",
    "with open(train_ann_path, 'r') as f:\n",
    "\tdata = json.load(f)\n",
    "\n",
    "# Only keep keypoint annotations\n",
    "annotations = data['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([262465, 17, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints = []\n",
    "for i in range(len(annotations)):\n",
    "\timg_keypoints = annotations[i][\"keypoints\"] # Keypoints for 1 image\n",
    "\n",
    "\t# Each person has 17 keypoints, 3 values for each\n",
    "\t# (x, y, visibility_flag)\n",
    "\tkeypoints.append([])\n",
    "\tfor j in range(0, len(img_keypoints), 3):\n",
    "\t\tkeypoints[i].append(img_keypoints[j:j+3])\n",
    "\n",
    "torch.tensor(keypoints).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([61720, 4, 3]), torch.Size([61720, 2, 3]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs = []\n",
    "train_targets = []\n",
    "\n",
    "# Only keep shoulders, hips, and feet\n",
    "# Indices for inputs\n",
    "input_indices = [5, 6, 11, 12] # Left Shoulder, Right Shoulder, Left Hip, Right Hip\n",
    "# Indices for targets\n",
    "target_indices = [15, 16] # Left Foot (Ankle), Right Foot (Ankle)\n",
    "\n",
    "for i in range(len(keypoints)):\n",
    "\tpoints = np.array(keypoints[i])[input_indices]\n",
    "\tif points[0][2] == 0 or points[1][2] == 0 or points[2][2] == 0 or points[3][2] == 0:\n",
    "\t\tcontinue\n",
    "\n",
    "\tlabel = np.array(keypoints[i])[target_indices]\n",
    "\tif label[0][2] == 0 or label[1][2] == 0:\n",
    "\t\tcontinue\n",
    "\n",
    "\ttrain_inputs.append(points)\n",
    "\ttrain_targets.append(label)\n",
    "\n",
    "torch.tensor(train_inputs).shape, torch.tensor(train_targets).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[198, 193,   2],\n",
       "        [243, 196,   2],\n",
       "        [197, 298,   2],\n",
       "        [228, 297,   2]]),\n",
       " array([[205, 475,   2],\n",
       "        [215, 453,   2]]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs[0], train_targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([61720, 4, 3]), torch.Size([61720, 2, 3]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load keypoints for testing\n",
    "test_ann_path = Path('./Data/coco2017/annotations/person_keypoints_val2017.json')\n",
    "with open(test_ann_path, 'r') as f:\n",
    "\tdata = json.load(f)\n",
    "\n",
    "test_annotations = data['annotations']\n",
    "keypoints = []\n",
    "for i in range(len(annotations)):\n",
    "\timg_keypoints = annotations[i][\"keypoints\"] # Keypoints for 1 image\n",
    "\n",
    "\t# Each person has 17 keypoints, 3 values for each\n",
    "\t# (x, y, visibility_flag)\n",
    "\tkeypoints.append([])\n",
    "\tfor j in range(0, len(img_keypoints), 3):\n",
    "\t\tkeypoints[i].append(img_keypoints[j:j+3])\n",
    "\n",
    "test_inputs = []\n",
    "test_targets = []\n",
    "\n",
    "# Only keep shoulders, hips, and feet\n",
    "# Indices for inputs\n",
    "input_indices = [5, 6, 11, 12] # Left Shoulder, Right Shoulder, Left Hip, Right Hip\n",
    "# Indices for targets\n",
    "target_indices = [15, 16] # Left Foot (Ankle), Right Foot (Ankle)\n",
    "\n",
    "for i in range(len(keypoints)):\n",
    "\tpoints = np.array(keypoints[i])[input_indices]\n",
    "\tif points[0][2] == 0 or points[1][2] == 0 or points[2][2] == 0 or points[3][2] == 0:\n",
    "\t\tcontinue\n",
    "\n",
    "\tlabel = np.array(keypoints[i])[target_indices]\n",
    "\tif label[0][2] == 0 or label[1][2] == 0:\n",
    "\t\tcontinue\n",
    "\n",
    "\ttest_inputs.append(points)\n",
    "\ttest_targets.append(label)\n",
    "\n",
    "torch.tensor(test_inputs).shape, torch.tensor(test_targets).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[198, 193,   2],\n",
       "        [243, 196,   2],\n",
       "        [197, 298,   2],\n",
       "        [228, 297,   2]]),\n",
       " array([[205, 475,   2],\n",
       "        [215, 453,   2]]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[0], test_targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class CocoKeypoints(Dataset):\n",
    "\tdef __init__(self, inputs, labels):\n",
    "\t\tsuper(CocoKeypoints, self).__init__()\n",
    "\t\tself.inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "\t\tself.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\t# Remove visibility from keypoints\n",
    "\t\treturn self.inputs[index].T[:2].T.flatten(), self.labels[index].T[:2].T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# Data loader\n",
    "train = CocoKeypoints(train_inputs, train_targets)\n",
    "test = CocoKeypoints(test_inputs, test_targets)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE,\n",
    "                         shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([198., 193., 243., 196., 197., 298., 228., 297.]),\n",
       " tensor([205., 475., 215., 453.]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointPredictor(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(KeypointPredictor, self).__init__()\n",
    "\t\tself.seq = nn.Sequential(\n",
    "\t\t\tnn.Linear(8, 64),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(64, 128),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(128, 256),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(256, 128),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(128, 64),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(64, 4)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = KeypointPredictor().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.HuberLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, leave=False, desc=f\"Epoch {epoch}\")\n",
    "    for data, target in loop:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        results = model(data)  # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(results, target)\n",
    "        loss.backward()  # Back propogation\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.inference_mode():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            results = model(data)\n",
    "            test_loss += loss_fn(results, target).item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test Loss {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.4509217321718193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.5224648056135344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.573404291683563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.5247613332214405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.556638284944051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.5144094517226354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.665778928481366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.483441400033502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.7290008650842768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 2.550735821951077\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "\ttrain(epoch)\n",
    "\ttest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"FeetPredict.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
